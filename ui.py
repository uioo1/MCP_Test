import streamlit as st
from langchain_openai import OpenAIEmbeddings
from langchain.schema import HumanMessage, AIMessage
import tools
import utils


def setup_sidebar():
    """
    ì‚¬ì´ë“œë°”ë¥¼ ì„¤ì •í•˜ê³  API í‚¤ ì…ë ¥ ë° ë¬¸ì„œ ì—…ë¡œë“œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        tuple: (api_key, uploaded_files, build_kb_clicked)
    """
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        api_key = st.text_input(
            "OpenAI API Key",
            type="password",
            placeholder="sk-...",
            help="OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        if api_key:
            if utils.validate_api_key(api_key):
                st.success("âœ… API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
            else:
                st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤ í˜•ì‹ì…ë‹ˆë‹¤")
        
        st.divider()
        
        st.header("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤")
        
        uploaded_files = st.file_uploader(
            "ë¬¸ì„œ ì—…ë¡œë“œ",
            type=['pdf', 'txt'],
            accept_multiple_files=True,
            help="PDF ë˜ëŠ” TXT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        
        if uploaded_files:
            st.info(f"ğŸ“„ {len(uploaded_files)}ê°œ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤")
            for file in uploaded_files:
                st.text(f"  â€¢ {file.name}")
        
        build_kb_clicked = st.button(
            "ğŸ”¨ ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•",
            disabled=not uploaded_files or not api_key,
            use_container_width=True
        )
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.chat_history = []
            st.rerun()
        
        st.divider()
        
        st.header("ğŸ¤– ëª¨ë¸ ì •ë³´")
        st.info("""
        **Simple ì§ˆë¬¸**: GPT-3.5-turbo
        **Complex ì§ˆë¬¸**: GPT-4-turbo-preview
        """)
        
        st.divider()
        
        st.caption("ğŸ’¡ Tip: ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return api_key, uploaded_files, build_kb_clicked


def render_chat_interface():
    """
    ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    st.header("ğŸ’¬ AI ê³ ê° ë¬¸ì˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ")
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.chat_history:
            if isinstance(message, HumanMessage):
                with st.chat_message("user"):
                    st.markdown(message.content)
            elif isinstance(message, AIMessage):
                with st.chat_message("assistant"):
                    st.markdown(message.content)
    
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    return user_input


def display_welcome_message():
    """
    í™˜ì˜ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    st.markdown("""
    ### ğŸ‘‹ í™˜ì˜í•©ë‹ˆë‹¤!
    
    ì´ ì‹œìŠ¤í…œì€ AIë¥¼ í™œìš©í•˜ì—¬ ê³ ê° ë¬¸ì˜ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    **ì‚¬ìš© ë°©ë²•:**
    1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”
    2. (ì„ íƒ) ì°¸ê³ í•  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•˜ì„¸ìš”
    3. ì•„ë˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”
    
    **íŠ¹ì§•:**
    - ğŸ¤– ìë™ ë¬¸ì˜ ë¶„ë¥˜ (Simple/Complex)
    - ğŸ“š RAG ê¸°ë°˜ ì •í™•í•œ ë‹µë³€ ìƒì„±
    - ğŸ§  ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•œ AI ë‹µë³€ ì œê³µ
    
    **ì‚¬ìš© ëª¨ë¸:**
    - Simple ì§ˆë¬¸: GPT-3.5-turbo
    - Complex ì§ˆë¬¸: GPT-4-turbo-preview
    """)


def display_status_message(message: str, type: str = "info"):
    """
    ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    
    Args:
        message: í‘œì‹œí•  ë©”ì‹œì§€
        type: ë©”ì‹œì§€ íƒ€ì… (info, success, warning, error)
    """
    if type == "info":
        st.info(message)
    elif type == "success":
        st.success(message)
    elif type == "warning":
        st.warning(message)
    elif type == "error":
        st.error(message)


def build_knowledge_base(uploaded_files, api_key):
    """
    ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        uploaded_files: ì—…ë¡œë“œëœ íŒŒì¼ë“¤
        api_key: OpenAI API í‚¤
    
    Returns:
        retriever: ìƒì„±ëœ ê²€ìƒ‰ê¸° ë˜ëŠ” None
    """
    try:
        with st.spinner("ğŸ“š ì§€ì‹ ë² ì´ìŠ¤ë¥¼ êµ¬ì¶• ì¤‘ì…ë‹ˆë‹¤..."):
            import os
            os.environ['OPENAI_API_KEY'] = api_key
            
            embeddings = OpenAIEmbeddings()
            retriever = tools.create_retriever(uploaded_files, embeddings)
            
            st.success("âœ… ì§€ì‹ ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!")
            return retriever
            
    except Exception as e:
        st.error(f"âŒ ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None


def process_user_query(question: str, retriever, api_key: str):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        retriever: RAG ê²€ìƒ‰ê¸°
        api_key: OpenAI API í‚¤
    
    Returns:
        str: AI ì‘ë‹µ
    """
    import os
    os.environ['OPENAI_API_KEY'] = api_key
    
    with st.spinner("ğŸ¤” ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        import graph
        
        result = graph.run_workflow(
            question=question,
            retriever=retriever,
            chat_history=st.session_state.chat_history
        )
        
        classification = result.get('classification', 'unknown')
        
        if classification == 'complex':
            model_used = "GPT-4-turbo-preview"
            st.info(f"ğŸ§  ë³µì¡í•œ ë¬¸ì˜ë¡œ ë¶„ë¥˜ - ì‚¬ìš© ëª¨ë¸: {model_used}")
        else:
            model_used = "GPT-3.5-turbo"
            st.info(f"âœ… ì¼ë°˜ ë¬¸ì˜ë¡œ ë¶„ë¥˜ - ì‚¬ìš© ëª¨ë¸: {model_used}")
        
        return result.get('answer', 'ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')